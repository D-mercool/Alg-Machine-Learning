{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики\n",
    "\n",
    "Меры качества классификации можно разбить на две большие группы: предназначенные для алгоритмов, выдающих номера классов, и для алгоритмов, выдающих оценки принадлежности к классам. К первой группе относятся доля правильных ответов, точность, полнота, F-мера. Ко второй — площади под ROC- или PR-кривой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics\n",
    "\n",
    "data = pd.read_csv('metrics.csv')\n",
    "d1 = data[data['true'] == data['pred']]\n",
    "d2 = data[data['true'] != data['pred']]\n",
    "\n",
    "tp = len(d1[d1['true'] == 1])\n",
    "tn = len(d1[d1['true'] == 0])\n",
    "fn = len(d2[d2['true'] == 1])\n",
    "fp = len(d2[d2['true'] == 0])\n",
    "\n",
    "print(tp, fp, fn, tn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "    \n",
    "    Precision (точность) — sklearn.metrics.precision_score\n",
    "    \n",
    "    Recall (полнота) — sklearn.metrics.recall_score\n",
    "    \n",
    "    F-мера — sklearn.metrics.f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535\n",
      "0.5584415584415584\n",
      "0.4215686274509804\n",
      "0.48044692737430167\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.accuracy_score(data['true'], data['pred']))\n",
    "print(sklearn.metrics.precision_score(data['true'], data['pred']))\n",
    "print(sklearn.metrics.recall_score(data['true'], data['pred']))\n",
    "print(sklearn.metrics.f1_score(data['true'], data['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC_AUC метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719187675070028\n",
      "0.7086834733893557\n",
      "0.6351540616246498\n",
      "0.6919267707082833\n"
     ]
    }
   ],
   "source": [
    "data_a = pd.read_csv('scores.csv')\n",
    "\n",
    "print(sklearn.metrics.roc_auc_score(data_a['true'], data_a['score_logreg']))\n",
    "print(sklearn.metrics.roc_auc_score(data_a['true'], data_a['score_svm']))\n",
    "print(sklearn.metrics.roc_auc_score(data_a['true'], data_a['score_knn']))\n",
    "print(sklearn.metrics.roc_auc_score(data_a['true'], data_a['score_tree']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6302521008403361\n",
      "0.6228070175438597\n",
      "0.6065573770491803\n",
      "0.6517857142857143\n"
     ]
    }
   ],
   "source": [
    "logred = pd.DataFrame(sklearn.metrics.precision_recall_curve(data_a['true'], data_a['score_logreg']))\n",
    "logred = logred.transpose()\n",
    "l = logred[logred[1] > 0.7].sort_values(by=0)\n",
    "print(l.iloc[-1][0])\n",
    "\n",
    "svm = pd.DataFrame(sklearn.metrics.precision_recall_curve(data_a['true'], data_a['score_svm']))\n",
    "svm = svm.transpose()\n",
    "s = svm[svm[1] > 0.7].sort_values(by=0)\n",
    "print(s.iloc[-1][0])\n",
    "\n",
    "knn = pd.DataFrame(sklearn.metrics.precision_recall_curve(data_a['true'], data_a['score_knn']))\n",
    "knn = knn.transpose()\n",
    "k = knn[knn[1] > 0.7].sort_values(by=0)\n",
    "print(k.iloc[-1][0])\n",
    "\n",
    "tree = pd.DataFrame(sklearn.metrics.precision_recall_curve(data_a['true'], data_a['score_tree']))\n",
    "tree = tree.transpose()\n",
    "t = tree[tree[1] > 0.7].sort_values(by=0)\n",
    "print(t.iloc[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Значит максимальной значение точности среди тех записей, для которых полнота не меньше, чем 0.7 у классификатора score_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
