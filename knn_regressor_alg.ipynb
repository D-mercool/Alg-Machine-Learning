{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия с помощью k-соседей\n",
    "Нам понадобится решать задачу регрессии с помощью метода k ближайших соседей — воспользуйтесь для этого классом sklearn.neighbors.KNeighborsRegressor. Метрика задается с помощью параметра metric, нас будет интересовать значение ’minkowski’. Параметр метрики Минковского задается с помощью параметра p данного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold #Кросс-валидация\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Приведем признаки в выборке к одному масштабу при помощи функции sklearn.preprocessing.scale.\n",
    "    \n",
    "    Переберите разные варианты параметра метрики p по сетке от 1 до 10 с таким шагом, чтобы всего было протестировано 200 вариантов (используйте функцию numpy.linspace). \n",
    "    \n",
    "    Используйте KNeighborsRegressor с n_neighbors=5 и weights='distance' — данный параметр добавляет в алгоритм веса, зависящие от расстояния до ближайших соседей. В качестве метрики качества используйте среднеквадратичную ошибку (параметр scoring='mean_squared_error' у cross_val_score; при использовании библиотеки scikit-learn версии 0.18.1 и выше необходимо указывать scoring='neg_mean_squared_error'). \n",
    "    \n",
    "    Качество оценивайте, как и в предыдущем задании, с помощью кросс-валидации по 5 блокам с random_state = 42, не забудьте включить перемешивание выборки (shuffle=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "#Обработка данных\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "y = scale(y)\n",
    "\n",
    "#Разбиение на 5 групп\n",
    "kf = KFold(n_splits = 5, random_state=42, shuffle=True)\n",
    "\n",
    "#Обучение модели\n",
    "mass = []\n",
    "for i in np.linspace(1, 10, 200):\n",
    "    rg = KNeighborsRegressor(n_neighbors=5, weights='distance', p=i)\n",
    "    rg.fit(X, y)\n",
    "    #Проверка качетсва разбиения модели на наборах\n",
    "    scores = cross_val_score(rg, X, y, cv=kf)\n",
    "    mass.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0.643497\n",
      "2      0.639041\n",
      "3      0.636697\n",
      "4      0.629828\n",
      "5      0.626985\n",
      "         ...   \n",
      "196    0.504215\n",
      "197    0.504201\n",
      "198    0.504188\n",
      "199    0.504036\n",
      "200    0.504028\n",
      "Length: 200, dtype: float64\n",
      "Качество на кросс-валидации оказалось оптимальным при p=1\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(mass, index=range(1,201))\n",
    "print(data.mean(axis=1))\n",
    "print('Качество на кросс-валидации оказалось оптимальным при p=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Главным параметром любого метрического алгоритма является функция расстояния (или метрика), используемая для измерения сходства между объектами. Можно использовать стандартный вариант (например, евклидову метрику), но гораздо более эффективным вариантом является подбор метрики под конкретную задачу. Один из подходов — использование той же евклидовой метрики, но с весами: каждой координате ставится в соответствие определенный коэффициент; чем он больше, тем выше вклад признака в итоговое расстояние. Веса настраиваются с целью оптимизации качества на отложенной выборке. Другой подход, о котором и пойдет речь в данном задании — выбор метрики из некоторого класса метрик. Мы возьмем за основу метрику Минковского:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
