{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение\n",
    "Линейные методы хорошо подходят для работы с разреженными данными — к таковым относятся, например, тексты. Это можно объяснить высокой скоростью обучения и небольшим количеством параметров, благодаря чему удается избежать переобучения.\n",
    "\n",
    "Линейная регрессия имеет несколько разновидностей в зависимости от того, какой регуляризатор используется. Мы будем работать с гребневой регрессией, где применяется квадратичный, или L2-регуляризатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гребневая регрессия (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge #Гребневая регрессия\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что признаки LocationNormalized и ContractTime являются строковыми, и поэтому с ними нельзя работать напрямую. Такие нечисловые признаки с неупорядоченными значениями называют категориальными или номинальными. Типичный подход к их обработке — кодирование категориального признака с m возможными значениями с помощью m бинарных признаков. Каждый бинарный признак соответствует одному из возможных значений категориального признака и является индикатором того, что на данном объекте он принимает данное значение. Данный подход иногда называют one-hot-кодированием. Воспользуйтесь им, чтобы перекодировать признаки LocationNormalized и ContractTime. Он уже реализован в классе sklearn.feature_extraction.DictVectorizer. Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('salary-train.csv')\n",
    "data['LocationNormalized'].fillna('nan', inplace=True)\n",
    "data['ContractTime'].fillna('nan', inplace=True)\n",
    "\n",
    "enc = DictVectorizer()\n",
    "X_train = enc.fit_transform(data[['LocationNormalized', 'ContractTime']].to_dict('records')) #to_dict преобразовывает в словарь\n",
    "X_test = enc.transform(data[['LocationNormalized', 'ContractTime']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Программа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('salary-train.csv')\n",
    "d1 = data['LocationNormalized'].str.lower()\n",
    "d2 = data['FullDescription'].str.lower()\n",
    "d3 = data['ContractTime'].str.lower()\n",
    "d4 = data['SalaryNormalized']\n",
    "\n",
    "d2 = d2.replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "data = pd.concat([d1, d2, d3, d4], axis=1)\n",
    "data['LocationNormalized'].fillna('nan', inplace=True)\n",
    "data['ContractTime'].fillna('nan', inplace=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5)\n",
    "X_train1 = vectorizer.fit_transform(data['FullDescription'])\n",
    "\n",
    "v = DictVectorizer()\n",
    "X_train2 = v.fit_transform(data[['LocationNormalized', 'ContractTime']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=241, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.hstack([X_train1, X_train2])\n",
    "y_train = data['SalaryNormalized']\n",
    "\n",
    "clf = Ridge(alpha=1,random_state=241)\n",
    "clf.fit(X_train[0], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56719.7900627 , 38211.27723995])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('salary_train_mini.csv')\n",
    "X_test1 = vectorizer.transform(data1['FullDescription'])\n",
    "X_test2 = v.fit_transform(data1[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X_test = np.hstack([X_test1, X_test2])\n",
    "\n",
    "clf.predict(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
